import streamlit as st
import pandas as pd
from docx import Document
from docx.shared import Pt
from docx.oxml.ns import qn
from docx.enum.text import WD_PARAGRAPH_ALIGNMENT, WD_LINE_SPACING
from docxtpl import DocxTemplate  # æ ¸å¿ƒï¼šç”¨æ–¼æ¨¡æ¿å¡«å……
from io import BytesIO
import google.generativeai as genai
import json
import os
from datetime import datetime
import gspread
from google.oauth2.service_account import Credentials

# ==========================================
# 0. é é¢åŸºæœ¬è¨­å®š
# ==========================================
st.set_page_config(
    page_title="æ•¸ä½ç”¢æ¥­ç½²æ”¿ç­–è¦åŠƒçµ„è¡Œæ”¿ç§˜æ›¸", 
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==========================================
# 1. ğŸ“Š æœ¬åœ°ç”¨é‡è¨˜å¸³ç³»çµ±
# ==========================================
USAGE_LOG_FILE = "usage_log.json"

def load_usage_data():
    today_str = datetime.now().strftime("%Y-%m-%d")
    default_data = {"date": today_str, "stats": {}}
    if not os.path.exists(USAGE_LOG_FILE):
        return default_data
    try:
        with open(USAGE_LOG_FILE, "r", encoding="utf-8") as f:
            data = json.load(f)
            if data.get("date") != today_str:
                return default_data 
            return data
    except:
        return default_data

def save_usage_data(data):
    with open(USAGE_LOG_FILE, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=4)

def update_usage_count(model_name, input_tokens, output_tokens):
    data = load_usage_data()
    if model_name not in data["stats"]:
        data["stats"][model_name] = {"count": 0, "total_tokens": 0}
    data["stats"][model_name]["count"] += 1
    data["stats"][model_name]["total_tokens"] += (input_tokens + output_tokens)
    save_usage_data(data)

# ==========================================
# 2. ğŸ¨ UI ç¾åŒ–
# ==========================================
def inject_custom_css():
    tech_wave_bg = """
    <svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 1440 320'>
      <path fill='none' stroke='%23C9CACA' stroke-width='1.5' stroke-opacity='0.5' d='M0,160L48,176C96,192,192,224,288,224C384,224,480,192,576,165.3C672,139,768,117,864,128C960,139,1056,181,1152,197.3C1248,213,1344,203,1392,197.3L1440,192' />
      <path fill='none' stroke='%231F323D' stroke-width='1' stroke-opacity='0.2' d='M0,224L48,213.3C96,203,192,181,288,181.3C384,181,480,203,576,218.7C672,235,768,245,864,229.3C960,213,1056,171,1152,149.3C1248,128,1344,128,1392,128L1440,128' />
    </svg>
    """
    tech_wave_bg = tech_wave_bg.replace('\n', '').strip()

    st.markdown(f"""
        <style>
        [data-testid="stSidebar"] {{
            background-color: rgba(180, 196, 63, 0.5);
            backdrop-filter: blur(10px);
            border-right: 1px solid rgba(180, 196, 63, 0.3);
        }}
        [data-testid="stSidebar"] .stMarkdown, 
        [data-testid="stSidebar"] h1, 
        [data-testid="stSidebar"] h2, 
        [data-testid="stSidebar"] h3, 
        [data-testid="stSidebar"] label,
        [data-testid="stSidebar"] .caption {{
            color: #1F323D !important;
        }}
        .stApp {{
            background-color: #ffffff;
            background-image: url("data:image/svg+xml;utf8,{tech_wave_bg}");
            background-size: cover;
            background-position: center;
            background-attachment: fixed;
        }}
        .block-container {{
            background-color: rgba(255, 255, 255, 0.95);
            border-radius: 20px;
            padding: 3rem;
            margin-top: 2rem;
            box-shadow: 0 10px 30px rgba(31, 50, 61, 0.08);
            border: 1px solid rgba(201, 202, 202, 0.3);
        }}
        div.stButton > button:first-child {{
            background: linear-gradient(135deg, #1F323D 0%, #354A56 100%);
            color: white;
            font-size: 18px;
            font-weight: bold;
            border-radius: 8px;
            border: none;
            padding: 0.6rem 1rem;
            width: 100%;
            transition: all 0.3s cubic-bezier(0.25, 0.8, 0.25, 1);
            box-shadow: 0 4px 12px rgba(31, 50, 61, 0.2);
        }}
        div.stButton > button:first-child:hover {{
            transform: translateY(-2px);
            box-shadow: 0 8px 16px rgba(31, 50, 61, 0.3);
            background: linear-gradient(135deg, #2A4250, #4A6273);
        }}
        .info-card {{
            background-color: #f8f9fa;
            padding: 20px;
            border-radius: 12px;
            border-left: 6px solid #B4C43F;
            margin-bottom: 25px;
            color: #333;
            font-size: 1.05rem;
        }}
        .usage-metric-box {{
            border: 1px solid #1F323D;
            border-radius: 10px;
            padding: 12px;
            text-align: center;
            box-shadow: 0 2px 4px rgba(0,0,0,0.05);
            transition: all 0.3s ease;
        }}
        .usage-metric-title {{ font-size: 0.9em; font-weight: 600; margin-bottom: 4px;}}
        .usage-metric-value {{ font-size: 1.4em; font-weight: 800; }}
        h1 {{ color: #1F323D; font-weight: 800; }}
        #MainMenu {{visibility: hidden;}}
        footer {{visibility: hidden;}}
        </style>
    """, unsafe_allow_html=True)

# ==========================================
# 3. ç³»çµ±æç¤ºè©
# ==========================================
SYSTEM_INSTRUCTION = """
ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„è¡Œæ”¿ç§˜æ›¸ã€‚è«‹åˆ†æä½¿ç”¨è€…æä¾›çš„æª”æ¡ˆï¼ˆæ–‡ä»¶ã€éŒ„éŸ³æˆ–åœ–ç‰‡ï¼‰ï¼Œä¸¦æ ¹æ“šä½¿ç”¨è€…çš„è¦æ±‚ç”¢å‡ºå°æ‡‰çš„ JSON è³‡æ–™ã€‚
è«‹åš´æ ¼éµå®ˆä»¥ä¸‹è¦å‰‡ï¼š

1. **Memo (æŒ‡å®šæ ¼å¼)**ï¼š
   è‹¥ä»»å‹™æ˜¯ Memoï¼Œè«‹å›å‚³ JSON åŒ…å«ä»¥ä¸‹æ¬„ä½ã€‚
   **é‡è¦ï¼šé‡å° 'method', 'official', 'note' ç­‰å‹¾é¸æ¬„ä½ï¼Œè«‹è¼¸å‡ºã€ŒåŒ…å«æ‰€æœ‰é¸é …çš„å®Œæ•´å­—ä¸²ã€ï¼Œä¸¦å°‡åˆ¤æ–·æ‡‰å‹¾é¸çš„é …ç›®ç¬¦è™Ÿæ”¹ç‚ºã€Œå¯¦å¿ƒæ–¹å¡Š â– ã€ï¼Œæœªé¸é …ç›®ç¶­æŒã€Œç©ºå¿ƒæ–¹å¡Š â–¡ã€ã€‚**
   {
       "time": "æ™‚é–“ (è«‹å®Œæ•´å¡«å¯«ï¼Œå¦‚ï¼š113å¹´12æœˆ25æ—¥ 14:00)",
       "location": "åœ°é»",
       "method": "æ–¹å¼ (ä¾‹å¦‚ï¼š'â–¡é›»è©± â–¡æ´»å‹• â– æœƒè­° â–¡å…¬æ–‡æ‰¹ç¤º â–¡å…¶ä»–')",
       "official": "é•·å®˜ (ä¾‹å¦‚ï¼š'â– éƒ¨é•· â–¡æ¬¡é•· â–¡ä¸»ä»»ç§˜æ›¸ â–¡ç«‹æ³•å§”å“¡ â–¡å…¶ä»–ï¼š')",
       "meeting_name": "æœƒè­°åç¨±",
       "chair": "ä¸»å¸­",
       "attendees": "å‡ºå¸­äººå“¡",
       "related_dept": "ç›¸é—œéƒ¨æœƒ",
       "guest_dept": "åˆ—å¸­å–®ä½",
       "conclusions": ["çµè«–1 (è«‹ä»¥æ¢åˆ—å¼å‘ˆç¾)", "çµè«–2"],
       "action_items": ["è¾¦ç†äº‹é …1 (è«‹ä»¥æ¢åˆ—å¼å‘ˆç¾)", "è¾¦ç†äº‹é …2"],
       "note": "é™„è¨€ (ä¾‹å¦‚ï¼š'â–¡è«‹å›é›»è©± â–¡è«‹æƒ è™• â– è«‹åƒé…Œ â–¡å…¶ä»–')",
       "filename_prefix": "å»ºè­°æª”å (ä¸å«å‰¯æª”å)"
   }

2. **ç°¡æ˜“é–‹æœƒé€šçŸ¥å–® (æŒ‡å®šæ ¼å¼)**ï¼š
   è‹¥ä»»å‹™æ˜¯é–‹æœƒé€šçŸ¥ï¼Œè«‹å›å‚³ JSON åŒ…å«ä»¥ä¸‹æ¬„ä½ï¼š
   {
       "date": "ç™¼æ–‡æ—¥æœŸ (ä¾‹å¦‚: 113å¹´12æœˆ25æ—¥)",
       "dept": "ç™¼æ–‡å–®ä½ (ä¾‹å¦‚: æ”¿ç­–è¦åŠƒçµ„)",
       "reason": "é–‹æœƒäº‹ç”±",
       "full_time": "é–‹æœƒå®Œæ•´æ™‚é–“ (ä¾‹å¦‚: 113å¹´12æœˆ30æ—¥(æ˜ŸæœŸäºŒ) ä¸‹åˆ 4:00 - 5:00)",
       "location": "åœ°é»",
       "host": "ä¸»æŒäºº",
       "attendees": "å‡ºå¸­äººå“¡ (è‹¥ç„¡è³‡è¨Šå¡«å¯« 'è©³å¦‚ç°½åˆ°è¡¨')",
       "note": "ç°¡è¿°/è¨è«–è­°é¡Œèªªæ˜",
       "agenda_table": [ ["æ™‚é–“1", "ä¸»é¡Œ1", "å‚™è¨»1"], ["æ™‚é–“2", "ä¸»é¡Œ2", "å‚™è¨»2"] ],
       "filename_prefix": "å»ºè­°æª”å"
   }

3. **è«‡åƒ (æŒ‡å®šæ­¸ç´é‚è¼¯)**ï¼š
   è‹¥ä»»å‹™æ˜¯è«‡åƒï¼Œè«‹å›å‚³ JSON åŒ…å«ä»¥ä¸‹ä¸‰å€‹ä¸»è¦å€å¡Šï¼š
   {
       "title": "è«‡åƒä¸»é¡Œ",
       "background": ["èƒŒæ™¯èªªæ˜é»1", "èƒŒæ™¯èªªæ˜é»2"], 
       "discussion_points": [
           {"subtitle": "å°æ¨™é¡Œ (5-10å­—)", "content": "è©³ç´°èªªæ˜ (50-100å­—)"},
           {"subtitle": "å°æ¨™é¡Œ (5-10å­—)", "content": "è©³ç´°èªªæ˜ (50-100å­—)"}
       ],
       "unit_opinion": "å–®ä½æ„è¦‹èˆ‡ç«‹å ´èªªæ˜ (è«‹æ•´åˆç‚ºä¸€æ®µå®Œæ•´çš„ç™¼è¨€å…§å®¹)",
       "filename_prefix": "å»ºè­°æª”å"
   }
   **é‚è¼¯è¦å‰‡ï¼š**
   - **èƒŒæ™¯èªªæ˜**ï¼šè«‹æ­¸ç´ 1-2 é»èƒŒæ™¯è³‡è¨Šã€‚
   - **è¨è«–é‡é»**ï¼šè«‹æä¾› 5-10 é»ã€‚æ¯é»å¿…é ˆåŒ…å«ä¸€å€‹ã€Œ5-10å­—çš„å°æ¨™é¡Œã€ä»¥åŠå°æ‡‰çš„å…§å®¹ã€‚
   - **å–®ä½æ„è¦‹**ï¼šè«‹åŸºæ–¼å–®ä½ç«‹å ´ï¼Œæå‡ºå…·é«”çš„ç™¼è¨€å»ºè­°æˆ–ç«‹å ´è²æ˜ã€‚

4. **æ•¸æ“šæå– (Excel)**ï¼š
   è«‹å›å‚³ä¸€å€‹ Listï¼ŒåŒ…å«å¤šå€‹ Dictionaryï¼Œæ¯å€‹ Dictionary ä»£è¡¨ä¸€è¡Œæ•¸æ“šã€‚

5. **èªè¨€èˆ‡ç¿»è­¯å¼·åˆ¶è¦å‰‡**ï¼š
   - **æ‰€æœ‰è¼¸å‡ºå…§å®¹å¿…é ˆç‚ºã€Œç¹é«”ä¸­æ–‡ (Traditional Chinese, Taiwan)ã€**ã€‚
   - è‹¥åŸå§‹è³‡æ–™åŒ…å«å¤–æ–‡ï¼Œè«‹å‹™å¿…å…ˆå°‡å…¶**ç¿»è­¯ä¸¦æ½¤é£¾**ç‚ºé€šé †çš„ç¹é«”ä¸­æ–‡ã€‚
"""

# ==========================================
# 4. Gemini API åˆ†æå‡½æ•¸
# ==========================================
def analyze_content_with_gemini(file_list, task_type, api_key, user_instruction=""):
    if not api_key:
        return {"error": "è«‹å…ˆåœ¨å´é‚Šæ¬„è¼¸å…¥ API Key"}
    if not file_list:
        return {"error": "è«‹è‡³å°‘ä¸Šå‚³ä¸€å€‹æª”æ¡ˆ"}

    genai.configure(api_key=api_key)
    generation_config = {
        "temperature": 0.2, 
        "response_mime_type": "application/json"
    }

    model_priority_list = [
        "gemini-2.5-flash",      
        "gemini-3.0-flash",      
        "gemini-2.5-flash-lite"  
    ]
    
    content_parts = []
    base_prompt = f"ä½ æ˜¯ä¸€ä½å°ˆæ¥­è¡Œæ”¿ç§˜æ›¸ã€‚è«‹åˆ†ææ¥ä¸‹ä¾†æä¾›çš„å¤šä»½æ–‡ä»¶ï¼Œä¸¦è£½ä½œï¼š{task_type}ã€‚è«‹æ³¨æ„ï¼šè‹¥ä¸åŒæ–‡ä»¶å…§å®¹æœ‰è¡çªï¼Œè«‹ä»¥ã€Œæ—¥æœŸè¼ƒæ–°ã€æˆ–ã€Œä½¿ç”¨è€…è£œå……æŒ‡ä»¤ã€ç‚ºä¸»ã€‚"
    content_parts.append(base_prompt)

    file_inventory = []

    for uploaded_file in file_list:
        file_name = uploaded_file.name
        file_inventory.append(file_name)
        file_bytes = uploaded_file.getvalue()
        mime_type = uploaded_file.type
        
        if file_name.lower().endswith('.m4a'):
             mime_type = 'audio/mp4'

        content_parts.append(f"\n=== æª”æ¡ˆé–‹å§‹ï¼š{file_name} ===\n")

        if mime_type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
            try:
                doc = Document(BytesIO(file_bytes))
                full_text = []
                for para in doc.paragraphs:
                    if para.text.strip():
                        full_text.append(para.text)
                for table in doc.tables:
                    for row in table.rows:
                        row_text = [cell.text for cell in row.cells]
                        full_text.append(" | ".join(row_text))
                
                extracted_text = "\n".join(full_text)
                content_parts.append(extracted_text)
            except Exception as e:
                return {"error": f"æª”æ¡ˆ {file_name} è®€å–å¤±æ•—: {str(e)}"}
        else:
            content_parts.append({
                "mime_type": mime_type,
                "data": file_bytes
            })
        
        content_parts.append(f"\n=== æª”æ¡ˆçµæŸï¼š{file_name} ===\n")

    final_instruction_block = f"""
    \n
    ---
    **è³‡æ–™æ¸…å–®**ï¼š{', '.join(file_inventory)}
    
    ã€é‡è¦ï¼šä½¿ç”¨è€…ç‰¹åˆ¥è£œå……æŒ‡ä»¤ã€‘
    è«‹åœ¨åˆ†æä¸Šè¿°æª”æ¡ˆæ™‚ï¼Œå„ªå…ˆéµå®ˆä»¥ä¸‹æŒ‡ç¤ºï¼š
    {user_instruction if user_instruction else "ç„¡ç‰¹åˆ¥æŒ‡ä»¤ï¼Œè«‹ä¾ç…§æ¨™æº–æ ¼å¼ç”¢å‡ºã€‚"}
    
    **æ³¨æ„**ï¼š
    1. è‹¥ä¸Šè¿°ã€Œä½¿ç”¨è€…æŒ‡ä»¤ã€èˆ‡æª”æ¡ˆå…§å®¹æœ‰å‡ºå…¥ï¼Œè«‹ä»¥ã€Œä½¿ç”¨è€…æŒ‡ä»¤ã€ç‚ºæº–ã€‚
    2. è«‹å‹™å¿…è¼¸å‡ºç´” JSON æ ¼å¼ã€‚
    ---
    """
    content_parts.append(final_instruction_block)

    status_container = st.status("ğŸ¤– AI è¡Œæ”¿ç§˜æ›¸æ­£åœ¨å¤šæ¨¡æ…‹åˆ†æä¸­...", expanded=True)
    last_error = ""

    for model_name in model_priority_list:
        try:
            status_container.write(f"æ­£åœ¨å‘¼å«æ¨¡å‹ï¼š**{model_name}** ...")
            model = genai.GenerativeModel(
                model_name=model_name,
                generation_config=generation_config,
                system_instruction=SYSTEM_INSTRUCTION
            )
            response = model.generate_content(content_parts)
            
            if not response.text:
                raise ValueError("API å›å‚³ç©ºå€¼")

            json_result = json.loads(response.text)
            
            if hasattr(response, 'usage_metadata'):
                usage = response.usage_metadata
                input_t = usage.prompt_token_count
                output_t = usage.candidates_token_count
                update_usage_count(model_name, input_t, output_t)
                json_result['_meta_info'] = {
                    "model": model_name,
                    "input_tokens": input_t,
                    "output_tokens": output_t,
                    "total_tokens": usage.total_token_count
                }

            status_container.update(label=f"âœ… åˆ†æå®Œæˆï¼ä½¿ç”¨æ¨¡å‹ï¼š{model_name}", state="complete", expanded=False)
            return json_result

        except Exception as e:
            error_msg = str(e)
            last_error = error_msg
            status_container.write(f"âš ï¸ {model_name} ç™¼ç”ŸéŒ¯èª¤: {error_msg}ï¼Œåˆ‡æ›å‚™æ´...")
            continue

    status_container.update(label="âŒ æ‰€æœ‰æ¨¡å‹çš†å¤±æ•—", state="error")
    return {"error": f"æ‰€æœ‰æ¨¡å‹å˜—è©¦çš†å¤±æ•—ã€‚æœ€å¾ŒéŒ¯èª¤: {last_error}"}

# ==========================================
# 5. æª”æ¡ˆç”Ÿæˆå‡½æ•¸
# ==========================================
def set_chinese_font(run, font_name='æ¨™æ¥·é«”', size_pt=12):
    run.font.name = 'Times New Roman'
    run.font.size = Pt(size_pt)
    r = run._element
    r.rPr.rFonts.set(qn('w:eastAsia'), font_name)

# --- Memo (æ¨¡æ¿æ¨¡å¼ + èˆŠç‰ˆå‚™æ´) ---
def create_memo_docx_legacy(data):
    doc = Document()
    style = doc.styles['Normal']
    style.font.name = 'Times New Roman'
    style.element.rPr.rFonts.set(qn('w:eastAsia'), 'æ¨™æ¥·é«”')
    style.font.size = Pt(12)
    doc.add_paragraph("âš ï¸ (å‚™æ´æ¨¡å¼) æœªåµæ¸¬åˆ° Template_Memo.docxï¼Œåƒ…åˆ—å‡ºç´”æ–‡å­—å…§å®¹ã€‚")
    doc.add_paragraph(f"æ™‚é–“ï¼š{data.get('time', '')}")
    doc.add_paragraph(f"å…§å®¹ï¼š\n{data.get('conclusions', '')}")
    bio = BytesIO()
    doc.save(bio)
    bio.seek(0)
    return bio, "Legacy_Memo.docx"

def create_memo_docx(data):
    default_template_path = "Template_Memo.docx"
    if not os.path.exists(default_template_path):
        return create_memo_docx_legacy(data)
    try:
        doc = DocxTemplate(default_template_path)
        context = {
            'time': data.get('time', ''),
            'location': data.get('location', ''),
            'method': data.get('method', ''),     
            'official': data.get('official', ''), 
            'meeting_name': data.get('meeting_name', ''),
            'chair': data.get('chair', ''),
            'attendees': data.get('attendees', ''),
            'related_dept': data.get('related_dept', ''),
            'guest_dept': data.get('guest_dept', ''),
            'conclusions': data.get('conclusions', []), 
            'action_items': data.get('action_items', []),
            'note': data.get('note', ''),
            'filename_prefix': data.get('filename_prefix', 'Memo')
        }
        doc.render(context)
        bio = BytesIO()
        doc.save(bio)
        bio.seek(0)
        return bio, f"{context['filename_prefix']}.docx"
    except Exception as e:
        st.error(f"âŒ Memo æ¨¡æ¿ç”Ÿæˆå¤±æ•—: {str(e)}")
        return create_memo_docx_legacy(data)

# --- é–‹æœƒé€šçŸ¥å–® (æ¨¡æ¿æ¨¡å¼ + èˆŠç‰ˆå‚™æ´) ---
def create_notice_docx_legacy(data):
    doc = Document()
    doc.add_paragraph("âš ï¸ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æ¨¡æ¿æª”æ¡ˆï¼Œä¸”å·²åˆ‡æ›è‡³å‚™æ´æ¨¡å¼ã€‚")
    bio = BytesIO()
    doc.save(bio)
    bio.seek(0)
    return bio, "Legacy_Notice.docx"

def create_notice_docx(data, custom_template=None):
    default_template_path = "Template_Notice.docx" 
    doc = None
    if custom_template:
        doc = DocxTemplate(custom_template)
    elif os.path.exists(default_template_path):
        doc = DocxTemplate(default_template_path)
    else:
        return create_notice_docx_legacy(data)
    try:
        agenda_list = []
        if 'agenda_table' in data and isinstance(data['agenda_table'], list):
            for item in data['agenda_table']:
                col1 = str(item[0]) if len(item) > 0 else ""
                col2 = str(item[1]) if len(item) > 1 else ""
                col3 = str(item[2]) if len(item) > 2 else ""
                agenda_list.append({'col1': col1, 'col2': col2, 'col3': col3})

        context = {
            'date': data.get('date', ''),
            'dept': data.get('dept', ''),
            'reason': data.get('reason', ''),
            'full_time': data.get('full_time', ''),
            'location': data.get('location', ''),
            'host': data.get('host', ''),
            'attendees': data.get('attendees', ''),
            'summary': data.get('note', ''),
            'agenda_table': agenda_list, 
            'filename_prefix': data.get('filename_prefix', 'MeetingNotice')
        }
        doc.render(context)
        bio = BytesIO()
        doc.save(bio)
        bio.seek(0)
        return bio, f"{context['filename_prefix']}.docx"
    except Exception as e:
        st.error(f"âŒ æ¨¡æ¿ç”Ÿæˆå¤±æ•—: {str(e)}")
        return create_notice_docx_legacy(data)

# --- è«‡åƒ (ç¶­æŒ Code æ¨¡å¼) ---
def create_talking_points_docx(data):
    doc = Document()
    style = doc.styles['Normal']
    style.font.name = 'Times New Roman'
    style.element.rPr.rFonts.set(qn('w:eastAsia'), 'æ¨™æ¥·é«”')
    style.font.size = Pt(12)
    
    p_title = doc.add_paragraph()
    r_title = p_title.add_run(data.get('title', 'è«‡åƒè³‡æ–™'))
    r_title.bold = True
    set_chinese_font(r_title, size_pt=18)
    p_title.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER
    doc.add_paragraph("-" * 30).alignment = WD_PARAGRAPH_ALIGNMENT.CENTER

    if data.get('background'):
        p_h1 = doc.add_paragraph()
        r_h1 = p_h1.add_run("ä¸€ã€èƒŒæ™¯èªªæ˜")
        r_h1.bold = True
        set_chinese_font(r_h1, size_pt=14)
        for item in data['background']:
            p = doc.add_paragraph(style='List Bullet')
            set_chinese_font(p.add_run(item))

    if data.get('discussion_points'):
        p_h2 = doc.add_paragraph()
        r_h2 = p_h2.add_run("äºŒã€è¨è«–é‡é»")
        r_h2.bold = True
        set_chinese_font(r_h2, size_pt=14)
        for item in data['discussion_points']:
            p = doc.add_paragraph(style='List Number')
            if 'subtitle' in item:
                r_sub = p.add_run(f"ã€{item['subtitle']}ã€‘")
                r_sub.bold = True
                set_chinese_font(r_sub)
            if 'content' in item:
                r_con = p.add_run(f"ï¼š{item['content']}")
                set_chinese_font(r_con)

    if data.get('unit_opinion'):
        p_h3 = doc.add_paragraph()
        r_h3 = p_h3.add_run("ä¸‰ã€å–®ä½æ„è¦‹")
        r_h3.bold = True
        set_chinese_font(r_h3, size_pt=14)
        p_op = doc.add_paragraph()
        p_op.paragraph_format.first_line_indent = Pt(24)
        set_chinese_font(p_op.add_run(data['unit_opinion']))

    bio = BytesIO()
    doc.save(bio)
    bio.seek(0)
    return bio, f"{data.get('filename_prefix', 'TalkingPoints')}.docx"

# --- Excel & Sheets ---
def create_excel(data_list):
    df = pd.DataFrame(data_list)
    bio = BytesIO()
    with pd.ExcelWriter(bio, engine='xlsxwriter') as writer:
        df.to_excel(writer, index=False, sheet_name='Data_Extraction')
    bio.seek(0)
    return bio, "Data_Extraction.xlsx"

def create_google_sheet(data, task_type, creds_dict, user_email=None):
    SCOPES = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']
    try:
        creds = Credentials.from_service_account_info(creds_dict, scopes=SCOPES)
        client = gspread.authorize(creds)
        title = f"{data.get('filename_prefix', 'Export')}_{datetime.now().strftime('%m%d_%H%M')}"
        sh = client.create(title)
        ws = sh.sheet1
        rows_to_write = []
        
        if task_type == "æ•¸æ“šæå– (Excel)":
             if isinstance(data, list) and len(data) > 0:
                 header = list(data[0].keys())
                 rows_to_write.append(header)
                 for item in data: rows_to_write.append(list(item.values()))
             else:
                 ws.update_acell('A1', 'ç„¡æ•¸æ“š')
        else:
            for k, v in data.items():
                if isinstance(v, list):
                    if not v: continue
                    if all(isinstance(x, str) for x in v):
                         rows_to_write.append([k, "\n".join(v)])
                    elif all(isinstance(x, dict) for x in v):
                         rows_to_write.append([k, "(è©³å¦‚ä¸‹è¡¨)"])
                         for sub_item in v:
                             rows_to_write.append(["", sub_item.get('subtitle',''), sub_item.get('content','')])
                else:
                    rows_to_write.append([k, str(v)])
        
        if rows_to_write: ws.update(rows_to_write)
        if user_email: sh.share(user_email, perm_type='user', role='writer')
        else: sh.share(None, perm_type='anyone', role='writer')
        return sh.url, "âœ… æˆåŠŸå»ºç«‹ Google Sheetï¼"
    except Exception as e:
        return None, f"âŒ éŒ¯èª¤: {str(e)}"

# ==========================================
# 6. Streamlit UI ä¸»ç¨‹å¼
# ==========================================
def main():
    inject_custom_css()

    with st.sidebar:
        st.title("âš™ï¸ è¨­å®šé¢æ¿")
        
        # é¡¯ç¤ºæ¨¡æ¿ç‹€æ…‹
        tpl_notice_exist = os.path.exists("Template_Notice.docx")
        tpl_memo_exist = os.path.exists("Template_Memo.docx")
        
        # -----------------------------------------------------
        # [ä¿®æ”¹] ç”¨é‡çµ±è¨ˆèˆ‡è¦–è¦ºåŒ–è­¦ç¤º
        # -----------------------------------------------------
        st.markdown("### ğŸ“Š ä»Šæ—¥ç”¨é‡çµ±è¨ˆ")
        usage_data = load_usage_data()
        target_models = ["gemini-2.5-flash", "gemini-3.0-flash", "gemini-2.5-flash-lite"]
        
        for m in target_models:
            count = usage_data["stats"].get(m, {}).get("count", 0)
            
            # å®šç¾©é¡è‰²é‚è¼¯
            if count >= 15:
                bg_color = "#D32F2F"   # æ·±ç´…
                text_color = "#FFFFFF" # ç™½å­—
                sub_text_color = "#EEEEEE" # æ¬¡è¦æ–‡å­—ä¹Ÿåç™½
            elif count >= 10:
                bg_color = "#FBC02D"   # é»ƒè‰²
                text_color = "#1F323D" # æ·±è‰²å­—
                sub_text_color = "#1F323D"
            else:
                bg_color = "rgba(255, 255, 255, 0.6)" # é è¨­ç™½
                text_color = "#1F323D"
                sub_text_color = "#1F323D"

            st.markdown(f"""
            <div class="usage-metric-box" style="margin-bottom: 8px; background-color: {bg_color};">
                <div class="usage-metric-title" style="color: {text_color};">{m}</div>
                <div class="usage-metric-value" style="color: {text_color};">
                    {count} <span style="font-size:0.5em;color: {sub_text_color};">æ¬¡</span>
                </div>
            </div>
            """, unsafe_allow_html=True)
        # -----------------------------------------------------

        st.markdown("---")
        
        with st.expander("â˜ï¸ Google Sheets è¨­å®š", expanded=False):
            uploaded_key = st.file_uploader("ä¸Šå‚³ JSON Key", type=['json'], key="sheet_key")
            user_email = st.text_input("æ‚¨çš„ Google Email (é¸å¡«)")
            
        api_key = st.text_input("ğŸ”‘ API Key", type="password", help="è«‹è¼¸å…¥æ‚¨çš„ Google Gemini API Key")
        
        st.subheader("ğŸ“ ä»»å‹™é¸æ“‡")
        task_mode = st.radio(
            "è«‹é¸æ“‡è¼¸å‡ºé¡å‹ï¼š",
            ("Memo (æŒ‡å®šæ ¼å¼)", "ç°¡æ˜“é–‹æœƒé€šçŸ¥å–® (æŒ‡å®šæ ¼å¼)", "è«‡åƒ", "æ•¸æ“šæå– (Excel)", "æœƒè­°ç´€éŒ„"),
            index=0
        )
        
        # å…§å»ºæ¨¡æ¿åµæ¸¬èˆ‡è¦†å¯« UI
        custom_template_file = None
        if task_mode == "ç°¡æ˜“é–‹æœƒé€šçŸ¥å–® (æŒ‡å®šæ ¼å¼)":
            st.markdown("---")
            st.markdown("##### ğŸ“„ æ¨¡æ¿ç‹€æ…‹")
            if tpl_notice_exist:
                st.caption("âœ… ä½¿ç”¨å…§å»ºï¼šTemplate_Notice.docx")
                if st.checkbox("æ‰‹å‹•ä¸Šå‚³å…¶ä»–æ¨¡æ¿ (è¦†å¯«)"):
                    custom_template_file = st.file_uploader("ä¸Šå‚³æš«ç”¨æ¨¡æ¿ (.docx)", type=['docx'])
            else:
                st.warning("âš ï¸ æœªåµæ¸¬åˆ°å…§å»ºæ¨¡æ¿")
                custom_template_file = st.file_uploader("è«‹ä¸Šå‚³æ¨¡æ¿ (.docx)", type=['docx'])
        
        if task_mode == "Memo (æŒ‡å®šæ ¼å¼)":
            st.markdown("---")
            st.markdown("##### ğŸ“„ æ¨¡æ¿ç‹€æ…‹")
            if tpl_memo_exist:
                st.caption("âœ… ä½¿ç”¨å…§å»ºï¼šTemplate_Memo.docx")
            else:
                st.warning("âš ï¸ æœªåµæ¸¬åˆ°å…§å»ºæ¨¡æ¿ (Template_Memo.docx)")
                st.caption("è«‹å°‡æ¨¡æ¿æª”æ¡ˆæ”¾å…¥è³‡æ–™å¤¾ï¼Œå¦å‰‡å°‡ä½¿ç”¨ç´”æ–‡å­—æ¨¡å¼")

        # æ¢ä»¶å¼è£œå……æŒ‡ä»¤
        user_instruction = ""
        if task_mode in ["è«‡åƒ", "æ•¸æ“šæå– (Excel)", "Memo (æŒ‡å®šæ ¼å¼)", "æœƒè­°ç´€éŒ„", "ç°¡æ˜“é–‹æœƒé€šçŸ¥å–® (æŒ‡å®šæ ¼å¼)"]:
            st.markdown("---")
            st.markdown(f"##### âœï¸ ç‰¹åˆ¥æŒ‡ç¤º (é¸å¡«)")
            hint_text = "ä¾‹å¦‚ï¼šè«‹ç‰¹åˆ¥è‘—é‡æ–¼... (æ­¤æŒ‡ä»¤æ¬Šé‡æœ€é«˜)"
            user_instruction = st.text_area("è£œå……æŒ‡ä»¤ (AI å°‡å„ªå…ˆéµå®ˆ)", placeholder=hint_text, height=100)

        st.caption("ADI Policy Planning AI Agent | Tech Wave Ed.")

    col1, col2 = st.columns([3, 1])
    with col1:
        st.title("ğŸ¤– æ•¸ä½ç”¢æ¥­ç½²æ”¿ç­–è¦åŠƒçµ„è¡Œæ”¿ç§˜æ›¸")
        st.markdown("#### è‡ªå‹•åŒ–å…¬æ–‡ç”Ÿæˆç³»çµ± | æ”¯æ´å¤šæª”æ¡ˆã€éŒ„éŸ³èˆ‡æ¨¡æ¿å¡«å……")
    with col2:
        st.markdown("")

    st.markdown('<div class="info-card">ğŸ’¡ ç³»çµ±æç¤ºï¼šæ”¯æ´å¤šæª”æ¡ˆä¸Šå‚³ã€‚è«‹åœ¨å·¦å´é¸æ“‡ä»»å‹™èˆ‡è¼¸å…¥æŒ‡ä»¤ï¼Œåˆ†æçµæœå°‡è‡ªå‹•å„ªåŒ–ç‚ºæ¨™æº–å…¬æ–‡æ ¼å¼ã€‚</div>', unsafe_allow_html=True)

    with st.container(border=True):
        uploaded_files = st.file_uploader(
            "ğŸ“‚ æ‹–æ”¾æª”æ¡ˆåˆ°é€™è£¡æˆ–é»æ“Šä¸Šå‚³ (å¯å¤šé¸)", 
            type=['docx', 'pdf', 'txt', 'wav', 'mp3', 'm4a', 'png', 'jpg', 'pptx'],
            accept_multiple_files=True
        )

    if uploaded_files:
        col_preview, col_action = st.columns([1, 2])
        with col_preview:
            st.info(f"ğŸ“ å·²ä¸Šå‚³ {len(uploaded_files)} å€‹æª”æ¡ˆ")
            for f in uploaded_files:
                st.caption(f"- {f.name}")
        
        with col_action:
            if st.button("ğŸš€ é–‹å§‹æ™ºæ…§åˆ†æ"):
                if not api_key:
                    st.toast("âš ï¸ è«‹å…ˆåœ¨å´é‚Šæ¬„è¼¸å…¥ API Key", icon="ğŸ”‘")
                else:
                    result = analyze_content_with_gemini(uploaded_files, task_mode, api_key, user_instruction)
                    if "error" in result:
                        st.error(result["error"])
                    else:
                        st.session_state['result_data'] = result
                        if '_meta_info' in result:
                             st.session_state['meta_info'] = result.pop('_meta_info')
                        else:
                             st.session_state['meta_info'] = None
                        st.rerun()

    if 'result_data' in st.session_state and st.session_state['result_data']:
        result_data = st.session_state['result_data']
        meta_info = st.session_state.get('meta_info')
        
        st.divider()
        st.subheader("ğŸ“Š åˆ†æçµæœ")
        if meta_info:
            m_col1, m_col2, m_col3 = st.columns(3)
            m_col1.metric("ä½¿ç”¨æ¨¡å‹", meta_info['model'])
            m_col2.metric("è¼¸å…¥ Token", f"{meta_info['input_tokens']:,}")
            m_col3.metric("è¼¸å‡º Token", f"{meta_info['output_tokens']:,}")

        tab1, tab2, tab3 = st.tabs(["ğŸ“¥ ä¸‹è¼‰ç”¢å‡º", "ğŸ” åŸå§‹è³‡æ–™ (JSON)", "ğŸ“‹ æ•¸æ“šè¡¨æ ¼"])

        with tab1:
            st.success("æ–‡ä»¶å·²ç”Ÿæˆï¼è«‹é»æ“Šä¸‹æ–¹æŒ‰éˆ•ä¸‹è¼‰ã€‚")
            if task_mode == "Memo (æŒ‡å®šæ ¼å¼)":
                file_bio, file_name = create_memo_docx(result_data)
                st.download_button("ğŸ“¥ ä¸‹è¼‰ Memo Word æª”", file_bio, file_name, "application/vnd.openxmlformats-officedocument.wordprocessingml.document", use_container_width=True)
            elif task_mode == "ç°¡æ˜“é–‹æœƒé€šçŸ¥å–® (æŒ‡å®šæ ¼å¼)":
                file_bio, file_name = create_notice_docx(result_data, custom_template_file)
                st.download_button("ğŸ“¥ ä¸‹è¼‰ é–‹æœƒé€šçŸ¥å–® Word æª”", file_bio, file_name, "application/vnd.openxmlformats-officedocument.wordprocessingml.document", use_container_width=True)
            elif task_mode == "è«‡åƒ":
                file_bio, file_name = create_talking_points_docx(result_data)
                st.download_button("ğŸ“¥ ä¸‹è¼‰ è«‡åƒ Word æª”", file_bio, file_name, "application/vnd.openxmlformats-officedocument.wordprocessingml.document", use_container_width=True)
            elif task_mode == "æ•¸æ“šæå– (Excel)":
                file_bio, file_name = create_excel(result_data)
                st.download_button("ğŸ“¥ ä¸‹è¼‰ Excel æ•¸æ“šè¡¨", file_bio, file_name, "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", use_container_width=True)
            else:
                st.download_button("ğŸ“¥ ä¸‹è¼‰æ–‡å­—æª” (.txt)", str(result_data), "result.txt", use_container_width=True)

            st.markdown("---")
            if st.button("ğŸ“¤ åŒæ­¥ç”Ÿæˆ Google Sheet", use_container_width=True):
                if uploaded_key is None:
                    st.error("âš ï¸ è«‹å…ˆåœ¨å´é‚Šæ¬„ä¸Šå‚³ Service Account JSON Key")
                else:
                    try:
                        stringio = BytesIO(uploaded_key.getvalue())
                        creds_dict = json.load(stringio)
                        with st.spinner("æ­£åœ¨å»ºç«‹ Google Sheet..."):
                            sheet_url, msg = create_google_sheet(result_data, task_mode, creds_dict, user_email)
                        if sheet_url:
                            st.success(msg)
                            st.markdown(f"ğŸ”— [é»æ“Šé–‹å•Ÿ Google Sheet]({sheet_url})")
                        else:
                            st.error(msg)
                    except Exception as e:
                        st.error(f"èªè­‰æª”æ¡ˆè®€å–éŒ¯èª¤: {e}")

        with tab2:
            st.json(result_data)

        with tab3:
            if task_mode == "ç°¡æ˜“é–‹æœƒé€šçŸ¥å–® (æŒ‡å®šæ ¼å¼)" and 'agenda_table' in result_data:
                st.dataframe(pd.DataFrame(result_data['agenda_table'], columns=['æ™‚é–“', 'ä¸»é¡Œ', 'å‚™è¨»']), use_container_width=True)
            elif task_mode == "è«‡åƒ" and 'discussion_points' in result_data:
                st.dataframe(pd.DataFrame(result_data['discussion_points']), use_container_width=True)
            elif task_mode == "æ•¸æ“šæå– (Excel)" and isinstance(result_data, list):
                st.dataframe(result_data, use_container_width=True)
            elif task_mode == "Memo (æŒ‡å®šæ ¼å¼)" and 'action_items' in result_data:
                st.caption("è¾¦ç†äº‹é …æ¸…å–®")
                st.dataframe(pd.DataFrame(result_data['action_items'], columns=['å¾…è¾¦äº‹é …']), use_container_width=True)
            else:
                st.info("æ­¤æ¨¡å¼ç„¡é è¦½è¡¨æ ¼")

if __name__ == "__main__":
    main()
